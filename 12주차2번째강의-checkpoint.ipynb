import random
import matplotlib as plt
#a function that evaluates one layer based
#on the neuron values in the preceding layer
def apply_layer(y_in,w,b):
    z=dot(w,y_in)+b
    return(1/(1+exp(-z)))
    
N0 = 2 #input layer size
N1 = 30 #hidden layer size
N2 = 1 #output layer size

#from input layer to hidden layer:
w1 = random.uniform(low=-10,high=+10,size=(N1,N0))#random weight :N1XN0 output size times input size해야함
b1 = random.uniform(low=-1,high=+1,size=N1)

#from hidden layer to output layer:
w2 = random.uniform(low=-10,high=+10,size=(N2,N1))
b2 = random.uniform(low=-1,high=+1,size=N2)

#weights that connect the input to the hidden layer
#weights that connect the hidden layer to the output layer

def apply_net(y_in,w1,b1,w2,b2):
    y1=apply_layer(y_in,w1,b1)
    y2=apply_layer(y1,w2,b2)
    return(y2)


#Note: this is NOT the most efficient way to do this! but simple
N = 50 #will create picture of size MXM
y_out = zeros([M,M]) #array MXM to hold the result

for j1 in range(M):
    for j2 in range(M):
        value0=float(j1)/M-0.5
        value1=float(j2)/M-0.5
        y_out[j1,j2]=apply_net([value0,value1],w1,b1,w2,b2)[0]
        
#display image
plt.imshow(y_out,origin='lower',extent=(-0.5,0.5,-0.5,0.5))
plt.colorbar()
plt.title("NN output as a function of input values")
plt.xlabel("y_2")
plt.ylabel("y_1")
plt.show()


